{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVmdhAjALQG6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/homestay_price/Homestays_Data.csv'\n",
        "df = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "UefpU9eLMfl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "scZoDhK4MilW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "nPGbn_NGMypT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop('log_price', axis=1)\n",
        "y = df['log_price']\n",
        "\n",
        "# Perform train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)"
      ],
      "metadata": {
        "id": "EZk9znU6M24e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "95df0e6HN3My"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "def impute_and_target_encode(X_train, y_train, X_test, k=20):\n",
        "    \"\"\"\n",
        "    Imputes missing neighborhoods using the nearest neighbor (Manhattan distance)\n",
        "    and then applies a smoothed (credibility-based) target encoding.\n",
        "\n",
        "    Args:\n",
        "        X_train (pd.DataFrame): Training features with 'latitude', 'longitude', 'neighbourhood'.\n",
        "        y_train (pd.Series): Training target (e.g., 'log_price').\n",
        "        X_test (pd.DataFrame): Test features with 'latitude', 'longitude', 'neighbourhood'.\n",
        "        k (int): The smoothing factor for credibility encoding. Higher values\n",
        "                 require more data for a category's mean to be trusted.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the transformed X_train and X_test DataFrames.\n",
        "    \"\"\"\n",
        "    X_train_processed = X_train.copy()\n",
        "    X_test_processed = X_test.copy()\n",
        "\n",
        "    train_known_hoods = X_train_processed[X_train_processed['neighbourhood'].notna()]\n",
        "\n",
        "    # Impute for training set\n",
        "    train_missing_mask = X_train_processed['neighbourhood'].isna()\n",
        "    if train_missing_mask.any():\n",
        "        coords_missing = X_train_processed.loc[train_missing_mask, ['latitude', 'longitude']].values\n",
        "        coords_known = train_known_hoods[['latitude', 'longitude']].values\n",
        "        distance_matrix = cdist(coords_missing, coords_known, metric='cityblock')\n",
        "        nearest_indices = np.argmin(distance_matrix, axis=1)\n",
        "        imputed_hoods = train_known_hoods['neighbourhood'].iloc[nearest_indices].values\n",
        "        X_train_processed.loc[train_missing_mask, 'neighbourhood'] = imputed_hoods\n",
        "\n",
        "    # Impute for test set using training data as reference\n",
        "    test_missing_mask = X_test_processed['neighbourhood'].isna()\n",
        "    if test_missing_mask.any():\n",
        "        coords_missing = X_test_processed.loc[test_missing_mask, ['latitude', 'longitude']].values\n",
        "        coords_known = train_known_hoods[['latitude', 'longitude']].values\n",
        "        distance_matrix = cdist(coords_missing, coords_known, metric='cityblock')\n",
        "        nearest_indices = np.argmin(distance_matrix, axis=1)\n",
        "        imputed_hoods = train_known_hoods['neighbourhood'].iloc[nearest_indices].values\n",
        "        X_test_processed.loc[test_missing_mask, 'neighbourhood'] = imputed_hoods\n",
        "\n",
        "    print(\"Imputation complete.\")\n",
        "\n",
        "    # Combine X_train and y_train for calculations\n",
        "    train_full = pd.concat([X_train_processed, y_train], axis=1)\n",
        "    target_name = y_train.name\n",
        "\n",
        "    # Calculate global mean\n",
        "    global_mean = y_train.mean()\n",
        "\n",
        "    # Calculate mean and count for each neighborhood\n",
        "    agg = train_full.groupby('neighbourhood')[target_name].agg(['mean', 'count'])\n",
        "\n",
        "    # Calculate the credibility weight (w) and the smoothed mean\n",
        "    local_mean = agg['mean']\n",
        "    n = agg['count']\n",
        "\n",
        "    weight = n / (n + k)\n",
        "\n",
        "    smoothed_mean = weight * local_mean + (1 - weight) * global_mean\n",
        "\n",
        "    # This is our new encoding map\n",
        "    encoding_map = smoothed_mean\n",
        "\n",
        "    print(f\"Global Mean log_price: {global_mean:.4f}\")\n",
        "    print(f\"K (smoothing factor): {k}\\n\")\n",
        "    print(\"--- Encoding Map (Neighborhood -> Smoothed Mean) ---\")\n",
        "    print(encoding_map)\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "\n",
        "    # Add the new encoded feature\n",
        "    X_train_processed['neighbourhood_encoded'] = X_train_processed['neighbourhood'].map(encoding_map)\n",
        "    X_test_processed['neighbourhood_encoded'] = X_test_processed['neighbourhood'].map(encoding_map)\n",
        "\n",
        "    # Fill any potential NaNs in the test set with the global mean\n",
        "    # This handles neighborhoods that are in test but not train\n",
        "    X_test_processed['neighbourhood_encoded'].fillna(global_mean, inplace=True)\n",
        "\n",
        "    print(\"Smoothed Target Encoding complete.\")\n",
        "\n",
        "    return X_train_processed, X_test_processed\n",
        "\n",
        "X_train, X_test = impute_and_target_encode(X_train, y_train, X_test)\n",
        "\n",
        "print(\"\\n--- Original X_train ---\\n\", X_train)\n",
        "print(\"\\n--- Transformed X_train ---\\n\", X_train)\n",
        "print(\"\\n--- Original X_test ---\\n\", X_test)\n",
        "print(\"\\n--- Transformed X_test ---\\n\", X_test)"
      ],
      "metadata": {
        "id": "OZ9s9TqFOAdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.isnull().sum()"
      ],
      "metadata": {
        "id": "wE020kDmSrCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation = X_train['neighbourhood_encoded'].corr(y_train)\n",
        "\n",
        "print(f\"Correlation between neighbourhood_encoded and y_train: {correlation:.4f}\")"
      ],
      "metadata": {
        "id": "AAKiKVQrSw-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def impute_with_median_and_indicator(X_train, X_test, columns):\n",
        "    \"\"\"\n",
        "    Imputes specified columns with the median calculated from the training set\n",
        "    and adds binary indicator columns to flag imputed values.\n",
        "\n",
        "    Args:\n",
        "        X_train (pd.DataFrame): Training features DataFrame.\n",
        "        X_test (pd.DataFrame): Test features DataFrame.\n",
        "        columns (list): A list of column names to impute.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the transformed X_train and X_test DataFrames.\n",
        "    \"\"\"\n",
        "    X_train_imputed = X_train.copy()\n",
        "    X_test_imputed = X_test.copy()\n",
        "\n",
        "    print(\"Starting Median Imputation\")\n",
        "    for col in columns:\n",
        "        median_val = X_train_imputed[col].median()\n",
        "        print(f\"Median for '{col}': {median_val}\")\n",
        "\n",
        "        X_train_imputed[f'{col}_is_missing'] = X_train_imputed[col].isna().astype(int)\n",
        "        X_test_imputed[f'{col}_is_missing'] = X_test_imputed[col].isna().astype(int)\n",
        "\n",
        "        X_train_imputed[col].fillna(median_val, inplace=True)\n",
        "        X_test_imputed[col].fillna(median_val, inplace=True)\n",
        "\n",
        "    print(\"Median imputation complete.\")\n",
        "    return X_train_imputed, X_test_imputed"
      ],
      "metadata": {
        "id": "5zRtiylpU5zM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_response_rate_to_numeric(df):\n",
        "    \"\"\"\n",
        "    Converts the 'host_response_rate' column to numeric by removing '%'\n",
        "    and coercing errors to NaN.\n",
        "    \"\"\"\n",
        "    df['host_response_rate'] = df['host_response_rate'].str.rstrip('%').astype('float') / 100.0\n",
        "    return df\n",
        "\n",
        "X_train = convert_response_rate_to_numeric(X_train)\n",
        "X_test = convert_response_rate_to_numeric(X_test)"
      ],
      "metadata": {
        "id": "r3KkzqXyz09Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "impute_cols = ['bathrooms', 'bedrooms', 'beds', 'host_response_rate']\n",
        "X_train, X_test = impute_with_median_and_indicator(\n",
        "    X_train, X_test, impute_cols\n",
        ")"
      ],
      "metadata": {
        "id": "LQBiTS1WuTXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "uH1CjzwzufLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "display(X_train.head())"
      ],
      "metadata": {
        "id": "8zihXpoGvGuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61ca2676"
      },
      "source": [
        "cols_to_drop = ['id', 'thumbnail_url', 'zipcode']\n",
        "X_train = X_train.drop(columns=cols_to_drop)\n",
        "X_test = X_test.drop(columns=cols_to_drop)\n",
        "\n",
        "print(\"Columns dropped successfully.\")\n",
        "display(X_train.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Distribution of 'number_of_reviews':\")\n",
        "display(X_train['number_of_reviews'].describe())\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(X_train['number_of_reviews'].dropna(), bins=50, kde=True)\n",
        "plt.title('Distribution of Number of Reviews')\n",
        "plt.xlabel('Number of Reviews')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nDistribution of 'review_scores_rating':\")\n",
        "display(X_train['review_scores_rating'].describe())\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(X_train['review_scores_rating'].dropna(), bins=20, kde=True)\n",
        "plt.title('Distribution of Review Scores Rating')\n",
        "plt.xlabel('Review Scores Rating')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6fxQQ_8R2DFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def calculate_bayesian_average_score(X_train, X_test, C=20):\n",
        "    \"\"\"\n",
        "    Calculates a credibility score using a Bayesian average.\n",
        "\n",
        "    This combines an item's average rating with the global average rating,\n",
        "    weighted by the number of reviews.\n",
        "\n",
        "    Args:\n",
        "        X_train (pd.DataFrame): Training features with 'review_scores_rating'\n",
        "                                and 'number_of_reviews'.\n",
        "        X_test (pd.DataFrame): Test features with 'review_scores_rating'\n",
        "                               and 'number_of_reviews'.\n",
        "        C (int): The smoothing factor or \"prior count\". A higher value\n",
        "                 means a listing needs more reviews for its own rating\n",
        "                 to be considered credible.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the transformed X_train and X_test DataFrames\n",
        "               with the new 'credibility_score' column.\n",
        "    \"\"\"\n",
        "    X_train_processed = X_train.copy()\n",
        "    X_test_processed = X_test.copy()\n",
        "\n",
        "    global_avg_rating = X_train_processed['review_scores_rating'].mean()\n",
        "    print(f\"Global Average Rating (from train set): {global_avg_rating:.2f}\")\n",
        "    print(f\"Smoothing Factor (C): {C}\")\n",
        "\n",
        "    X_train_processed['review_scores_rating'].fillna(global_avg_rating, inplace=True)\n",
        "    X_test_processed['review_scores_rating'].fillna(global_avg_rating, inplace=True)\n",
        "\n",
        "    def calculate_score(row):\n",
        "        n = row['number_of_reviews']\n",
        "        item_rating = row['review_scores_rating']\n",
        "\n",
        "        # The core Bayesian average formula\n",
        "        numerator = (C * global_avg_rating) + (n * item_rating)\n",
        "        denominator = C + n\n",
        "\n",
        "        return numerator / denominator\n",
        "\n",
        "    X_train_processed['credibility_score'] = X_train_processed.apply(calculate_score, axis=1)\n",
        "    X_test_processed['credibility_score'] = X_test_processed.apply(calculate_score, axis=1)\n",
        "\n",
        "    print(\"'credibility_score' feature created successfully.\")\n",
        "\n",
        "    return X_train_processed, X_test_processed\n",
        "\n",
        "X_train, X_test = calculate_bayesian_average_score(\n",
        "    X_train, X_test, C=20\n",
        ")"
      ],
      "metadata": {
        "id": "TiDmNrbM16iY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head(3)"
      ],
      "metadata": {
        "id": "MNFVt8Xg2bQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.info()"
      ],
      "metadata": {
        "id": "9ekV1jsq2dH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in ['host_has_profile_pic', 'host_identity_verified']:\n",
        "    X_train[col] = X_train[col].map({'t': 1, 'f': 0})\n",
        "    X_test[col] = X_test[col].map({'t': 1, 'f': 0})\n",
        "\n",
        "print(\"Replaced 't' with 1 and 'f' with 0 for 'host_has_profile_pic' and 'host_identity_verified'.\")\n",
        "display(X_train[['host_has_profile_pic', 'host_identity_verified']].head())"
      ],
      "metadata": {
        "id": "_bi6cYaMO5Hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52869dfe"
      },
      "source": [
        "for col in ['host_has_profile_pic', 'host_identity_verified']:\n",
        "    X_train[col].fillna(0, inplace=True)\n",
        "    X_test[col].fillna(0, inplace=True)\n",
        "\n",
        "print(\"Imputed missing values with 0 for 'host_has_profile_pic' and 'host_identity_verified'.\")\n",
        "display(X_train[['host_has_profile_pic', 'host_identity_verified']].isnull().sum())\n",
        "display(X_test[['host_has_profile_pic', 'host_identity_verified']].isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.info()"
      ],
      "metadata": {
        "id": "SMcX9ng6Pyhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['last_review'] = pd.to_datetime(X_train['last_review'], errors='coerce')\n",
        "X_test['last_review'] = pd.to_datetime(X_test['last_review'], errors='coerce')\n",
        "\n",
        "fixed_date = pd.to_datetime('2024-01-01')\n",
        "\n",
        "X_train['relevance'] = (fixed_date - X_train['last_review']).dt.days\n",
        "X_test['relevance'] = (fixed_date - X_test['last_review']).dt.days\n",
        "\n",
        "print(\"Created 'relevance' feature.\")\n",
        "display(X_train[['last_review', 'relevance']].head())"
      ],
      "metadata": {
        "id": "dgNgx9xAP39D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['last_review'] = pd.to_datetime(X_train['last_review'], errors='coerce')\n",
        "X_train['first_review'] = pd.to_datetime(X_train['first_review'], errors='coerce')\n",
        "X_test['last_review'] = pd.to_datetime(X_test['last_review'], errors='coerce')\n",
        "X_test['first_review'] = pd.to_datetime(X_test['first_review'], errors='coerce')\n",
        "\n",
        "X_train['active_period'] = (X_train['last_review'] - X_train['first_review']).dt.days\n",
        "X_test['active_period'] = (X_test['last_review'] - X_test['first_review']).dt.days\n",
        "\n",
        "print(\"Created 'active_period' feature.\")\n",
        "display(X_train[['first_review', 'last_review', 'active_period']].head())"
      ],
      "metadata": {
        "id": "6IN82q1JRkwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.drop(columns=['last_review'])\n",
        "X_test = X_test.drop(columns=['last_review'])\n",
        "\n",
        "imputation_value = 14608\n",
        "X_train['relevance'].fillna(imputation_value, inplace=True)\n",
        "X_test['relevance'].fillna(imputation_value, inplace=True)\n",
        "\n",
        "print(\"Removed 'last_review' and imputed 'relevance'.\")\n",
        "display(X_train[['relevance']].isnull().sum())\n",
        "display(X_test[['relevance']].isnull().sum())"
      ],
      "metadata": {
        "id": "3fyFa99MRAi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['active_period'].fillna(0, inplace=True)\n",
        "X_test['active_period'].fillna(0, inplace=True)\n",
        "\n",
        "print(\"Imputed missing values with 0 for 'active_period'.\")\n",
        "display(X_train['active_period'].isnull().sum())\n",
        "display(X_test['active_period'].isnull().sum())"
      ],
      "metadata": {
        "id": "09-ujxG1SAFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.info()"
      ],
      "metadata": {
        "id": "UYSEaAzvRV6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61491cd8"
      },
      "source": [
        "X_train['host_since'] = pd.to_datetime(X_train['host_since'], errors='coerce')\n",
        "X_test['host_since'] = pd.to_datetime(X_test['host_since'], errors='coerce')\n",
        "\n",
        "fixed_date = pd.to_datetime('2024-01-01')\n",
        "\n",
        "# Calculate host tenure in days\n",
        "X_train['host_tenure'] = (fixed_date - X_train['host_since']).dt.days\n",
        "X_test['host_tenure'] = (fixed_date - X_test['host_since']).dt.days\n",
        "\n",
        "# Impute missing 'host_tenure' with the median from the training set and add indicator\n",
        "host_tenure_median = X_train['host_tenure'].median()\n",
        "X_train['host_tenure_is_missing'] = X_train['host_tenure'].isna().astype(int)\n",
        "X_test['host_tenure_is_missing'] = X_test['host_tenure'].isna().astype(int)\n",
        "X_train['host_tenure'].fillna(host_tenure_median, inplace=True)\n",
        "X_test['host_tenure'].fillna(host_tenure_median, inplace=True)\n",
        "\n",
        "\n",
        "print(\"Created 'host_tenure' feature and imputed missing values.\")\n",
        "display(X_train[['host_since', 'host_tenure', 'host_tenure_is_missing']].head())\n",
        "display(X_train['host_tenure'].isnull().sum())\n",
        "display(X_test['host_tenure'].isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.info()"
      ],
      "metadata": {
        "id": "EHkhEJKJSwaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.drop(columns=['first_review', 'host_since'])\n",
        "X_test = X_test.drop(columns=['first_review', 'host_since'])\n",
        "\n",
        "print(\"Removed 'first_review' and 'host_since' columns.\")\n",
        "display(X_train.head())"
      ],
      "metadata": {
        "id": "M8WVy_v5SxeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing values in X_train:\")\n",
        "display(X_train.isnull().sum())\n",
        "\n",
        "print(\"\\nMissing values in X_test:\")\n",
        "display(X_test.isnull().sum())"
      ],
      "metadata": {
        "id": "VUy4KnfpS535"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head(5)"
      ],
      "metadata": {
        "id": "lYs1OWD_S_uT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols_to_plot = ['property_type', 'room_type', 'bed_type', 'city']\n",
        "\n",
        "for col in categorical_cols_to_plot:\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.countplot(data=X_train, y=col, order=X_train[col].value_counts().index, palette='viridis')\n",
        "    plt.title(f'Distribution of {col}')\n",
        "    plt.xlabel('Count')\n",
        "    plt.ylabel(col)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "x5N91VMYTIYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bayesian_target_encode(X_train, y_train, X_test, column_name, k=20):\n",
        "    \"\"\"\n",
        "    Applies a Bayesian (smoothed) target encoding to a specified column.\n",
        "\n",
        "    This method blends the category's local average target value with the\n",
        "    global average, weighted by the category's size (credibility).\n",
        "\n",
        "    Args:\n",
        "        X_train (pd.DataFrame): Training features DataFrame.\n",
        "        y_train (pd.Series): Training target Series (e.g., 'log_price').\n",
        "        X_test (pd.DataFrame): Test features DataFrame.\n",
        "        column_name (str): The name of the categorical column to encode\n",
        "                           (e.g., 'property_type').\n",
        "        k (int): The smoothing factor. A higher value requires more data for a\n",
        "                 category's mean to be trusted.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the transformed X_train and X_test DataFrames\n",
        "               with the new encoded column.\n",
        "    \"\"\"\n",
        "    X_train_encoded = X_train.copy()\n",
        "    X_test_encoded = X_test.copy()\n",
        "\n",
        "    print(f\"--- Starting Bayesian Target Encoding for '{column_name}' ---\")\n",
        "\n",
        "    train_full = pd.concat([X_train_encoded, y_train], axis=1)\n",
        "    target_name = y_train.name\n",
        "\n",
        "    global_mean = y_train.mean()\n",
        "    print(f\"Global Mean ('{target_name}'): {global_mean:.4f}\")\n",
        "    print(f\"Smoothing Factor (k): {k}\")\n",
        "\n",
        "    agg = train_full.groupby(column_name)[target_name].agg(['mean', 'count'])\n",
        "\n",
        "    weight = agg['count'] / (agg['count'] + k)\n",
        "\n",
        "    smoothed_mean = weight * agg['mean'] + (1 - weight) * global_mean\n",
        "\n",
        "    encoding_map = smoothed_mean\n",
        "\n",
        "    new_col_name = f'{column_name}_encoded'\n",
        "    X_train_encoded[new_col_name] = X_train_encoded[column_name].map(encoding_map)\n",
        "    X_test_encoded[new_col_name] = X_test_encoded[column_name].map(encoding_map)\n",
        "\n",
        "    X_test_encoded[new_col_name].fillna(global_mean, inplace=True)\n",
        "\n",
        "    print(f\"Bayesian encoding complete. New column created: '{new_col_name}'\")\n",
        "\n",
        "    return X_train_encoded, X_test_encoded"
      ],
      "metadata": {
        "id": "HDc3_kv8UKe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = bayesian_target_encode(\n",
        "    X_train, y_train, X_test,\n",
        "    column_name='property_type', k=10\n",
        ")"
      ],
      "metadata": {
        "id": "8QgGdRWDUmYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head(5)"
      ],
      "metadata": {
        "id": "GQPblQ1BUvqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['cleaning_fee'] = X_train['cleaning_fee'].map({False: 0, True: 1})\n",
        "X_test['cleaning_fee'] = X_test['cleaning_fee'].map({False: 0, True: 1})\n",
        "\n",
        "print(\"Converted 'cleaning_fee' to numeric.\")\n",
        "display(X_train[['cleaning_fee']].head())"
      ],
      "metadata": {
        "id": "EKR5-QR4Uxpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def apply_tfidf_to_name(X_train, X_test, max_features=100):\n",
        "    \"\"\"\n",
        "    Applies TF-IDF vectorization to the 'name' column of the datasets.\n",
        "\n",
        "    Args:\n",
        "        X_train (pd.DataFrame): Training features DataFrame with a 'name' column.\n",
        "        X_test (pd.DataFrame): Test features DataFrame with a 'name' column.\n",
        "        max_features (int): The maximum number of top TF-IDF features to create.\n",
        "                            This helps control the dimensionality of the output.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "               - X_train_processed (pd.DataFrame): The training DataFrame with new TF-IDF features.\n",
        "               - X_test_processed (pd.DataFrame): The test DataFrame with new TF-IDF features.\n",
        "    \"\"\"\n",
        "    X_train_processed = X_train.copy()\n",
        "    X_test_processed = X_test.copy()\n",
        "\n",
        "    print(\"Applying TF-IDF to 'name' column\")\n",
        "\n",
        "    X_train_processed['name'].fillna('missing', inplace=True)\n",
        "    X_test_processed['name'].fillna('missing', inplace=True)\n",
        "\n",
        "    # Initialize the TfidfVectorizer\n",
        "    # stop_words='english': Removes common English words (like 'a', 'the', 'in').\n",
        "    # max_features: Limits the number of output columns to the top N most important words.\n",
        "    # ngram_range=(1, 2): Considers both single words (unigrams) and two-word phrases (bigrams).\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        stop_words='english',\n",
        "        max_features=max_features,\n",
        "        ngram_range=(1, 2)\n",
        "    )\n",
        "\n",
        "    X_train_tfidf = vectorizer.fit_transform(X_train_processed['name'])\n",
        "\n",
        "    # Transform the test data using the already-fitted vectorizer\n",
        "    # This ensures that the same vocabulary and weights are applied.\n",
        "    X_test_tfidf = vectorizer.transform(X_test_processed['name'])\n",
        "\n",
        "    tfidf_train_df = pd.DataFrame(\n",
        "        X_train_tfidf.toarray(),\n",
        "        columns=[f'tfidf_{word}' for word in vectorizer.get_feature_names_out()],\n",
        "        index=X_train_processed.index\n",
        "    )\n",
        "\n",
        "    tfidf_test_df = pd.DataFrame(\n",
        "        X_test_tfidf.toarray(),\n",
        "        columns=[f'tfidf_{word}' for word in vectorizer.get_feature_names_out()],\n",
        "        index=X_test_processed.index\n",
        "    )\n",
        "\n",
        "    X_train_processed = pd.concat([X_train_processed.drop(columns=['name']), tfidf_train_df], axis=1)\n",
        "    X_test_processed = pd.concat([X_test_processed.drop(columns=['name']), tfidf_test_df], axis=1)\n",
        "\n",
        "    print(f\"TF-IDF complete. Added {len(vectorizer.get_feature_names_out())} new features.\")\n",
        "\n",
        "    return X_train_processed, X_test_processed"
      ],
      "metadata": {
        "id": "3ASXDVuVVOKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = apply_tfidf_to_name(X_train, X_test, max_features=10)"
      ],
      "metadata": {
        "id": "1X17nzM9WkQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head(5)"
      ],
      "metadata": {
        "id": "_B8iaQ1_Wrlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['instant_bookable'] = X_train['instant_bookable'].map({'f': 0, 't': 1})\n",
        "X_test['instant_bookable'] = X_test['instant_bookable'].map({'f': 0, 't': 1})\n",
        "\n",
        "print(\"Converted 'instant_bookable' to numeric.\")\n",
        "display(X_train[['instant_bookable']].head())"
      ],
      "metadata": {
        "id": "FJE6oSsOWt8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.info()"
      ],
      "metadata": {
        "id": "PN_Bcok3XWy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment"
      ],
      "metadata": {
        "id": "faTpmIB2X-Ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "def apply_vader_sentiment(X_train, X_test, column_name):\n",
        "    \"\"\"\n",
        "    Applies VADER sentiment analysis to a specified text column and adds\n",
        "    the sentiment scores as new features.\n",
        "\n",
        "    Args:\n",
        "        X_train (pd.DataFrame): Training features DataFrame.\n",
        "        X_test (pd.DataFrame): Test features DataFrame.\n",
        "        column_name (str): The name of the text column to analyze (e.g., 'description').\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "               - X_train_processed (pd.DataFrame): The training DataFrame with new sentiment features.\n",
        "               - X_test_processed (pd.DataFrame): The test DataFrame with new sentiment features.\n",
        "    \"\"\"\n",
        "    X_train_processed = X_train.copy()\n",
        "    X_test_processed = X_test.copy()\n",
        "\n",
        "    print(f\"--- Applying VADER Sentiment Analysis to '{column_name}' column ---\")\n",
        "\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "    X_train_processed[column_name].fillna('', inplace=True)\n",
        "    X_test_processed[column_name].fillna('', inplace=True)\n",
        "\n",
        "    def get_sentiment_scores(text):\n",
        "        # The polarity_scores method returns a dictionary with neg, neu, pos, and compound scores\n",
        "        scores = analyzer.polarity_scores(text)\n",
        "        return pd.Series(scores)\n",
        "\n",
        "    train_sentiments = X_train_processed[column_name].apply(get_sentiment_scores)\n",
        "    train_sentiments.columns = [f'vader_{col}_{column_name}' for col in train_sentiments.columns]\n",
        "    X_train_processed = pd.concat([X_train_processed, train_sentiments], axis=1)\n",
        "\n",
        "    test_sentiments = X_test_processed[column_name].apply(get_sentiment_scores)\n",
        "    test_sentiments.columns = [f'vader_{col}_{column_name}' for col in test_sentiments.columns]\n",
        "    X_test_processed = pd.concat([X_test_processed, test_sentiments], axis=1)\n",
        "\n",
        "    print(f\"✅ VADER analysis complete. Added 4 new sentiment features.\")\n",
        "\n",
        "    return X_train_processed, X_test_processed"
      ],
      "metadata": {
        "id": "Ahtjw7j3XYZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = apply_vader_sentiment(\n",
        "    X_train, X_test, column_name='description'\n",
        ")"
      ],
      "metadata": {
        "id": "sWe4CnN7YHpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head(5)"
      ],
      "metadata": {
        "id": "4PV1Qi6MYOn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.drop(columns=['description'])\n",
        "X_test = X_test.drop(columns=['description'])\n",
        "\n",
        "print(\"Removed 'description' column.\")\n",
        "display(X_train.head())"
      ],
      "metadata": {
        "id": "X-_bS60aZT5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to clean the amenities list\n",
        "def clean_amenities(amenities):\n",
        "    # Remove the curly braces and quotes\n",
        "    cleaned_amenities = amenities.replace('{', '').replace('}', '').replace('\"', '')\n",
        "    return cleaned_amenities\n",
        "\n",
        "# Apply the cleaning function to the amenities column\n",
        "X_train['cleaned_amenities'] = X_train['amenities'].apply(clean_amenities)\n",
        "X_test['cleaned_amenities'] = X_test['amenities'].apply(clean_amenities)"
      ],
      "metadata": {
        "id": "LzdWGjx7ZdiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head(5)"
      ],
      "metadata": {
        "id": "gEgZtaBd2swt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.drop(columns=['amenities'])\n",
        "X_test = X_test.drop(columns=['amenities'])\n",
        "\n",
        "print(\"Removed 'amenities' column.\")\n",
        "display(X_train.head())"
      ],
      "metadata": {
        "id": "9gpqeYGv2vYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.rename(columns={'cleaned_amenities': 'amenities'})\n",
        "X_test = X_test.rename(columns={'cleaned_amenities': 'amenities'})\n",
        "\n",
        "print(\"Renamed 'cleaned_amenities' to 'amenities'.\")\n",
        "display(X_train.head())"
      ],
      "metadata": {
        "id": "ooeu1zfA26Yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "def cluster_amenities_with_bert(X_train, X_test, max_k=15):\n",
        "    \"\"\"\n",
        "    Generates BERT embeddings for the 'amenities' column, finds the optimal\n",
        "    number of clusters using the silhouette method, and adds cluster labels\n",
        "    as a new feature.\n",
        "\n",
        "    Args:\n",
        "        X_train (pd.DataFrame): Training features with an 'amenities' column.\n",
        "        X_test (pd.DataFrame): Test features with an 'amenities' column.\n",
        "        max_k (int): The maximum number of clusters to test for optimality.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the transformed X_train and X_test DataFrames\n",
        "               with the new 'amenity_cluster' feature.\n",
        "    \"\"\"\n",
        "    X_train_processed = X_train.copy()\n",
        "    X_test_processed = X_test.copy()\n",
        "\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "    train_amenities = X_train_processed['amenities'].fillna('').tolist()\n",
        "    test_amenities = X_test_processed['amenities'].fillna('').tolist()\n",
        "\n",
        "    train_embeddings = model.encode(train_amenities, show_progress_bar=True)\n",
        "\n",
        "    print(f\"\\nFinding optimal k (up to max_k={max_k})\")\n",
        "    silhouette_scores = {}\n",
        "    k_range = range(2, max_k + 1)\n",
        "\n",
        "    for k in k_range:\n",
        "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "        kmeans.fit(train_embeddings)\n",
        "        score = silhouette_score(train_embeddings, kmeans.labels_)\n",
        "        silhouette_scores[k] = score\n",
        "        print(f\"  - k={k}, Silhouette Score: {score:.4f}\")\n",
        "\n",
        "    if not silhouette_scores:\n",
        "        print(\"Could not determine optimal k. Defaulting to 3.\")\n",
        "        optimal_k = 3\n",
        "    else:\n",
        "        optimal_k = max(silhouette_scores, key=silhouette_scores.get)\n",
        "\n",
        "    print(f\"\\nOptimal number of clusters found: k = {optimal_k}\")\n",
        "\n",
        "    print(f\"Training final K-Means model with k={optimal_k}\")\n",
        "    final_kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "    final_kmeans.fit(train_embeddings)\n",
        "\n",
        "    X_train_processed['amenity_cluster'] = final_kmeans.labels_\n",
        "\n",
        "    print(\"Generating embeddings for test data and predicting clusters\")\n",
        "    test_embeddings = model.encode(test_amenities, show_progress_bar=True)\n",
        "    test_clusters = final_kmeans.predict(test_embeddings)\n",
        "    X_test_processed['amenity_cluster'] = test_clusters\n",
        "\n",
        "    print(\"\\n Amenity clustering complete.\")\n",
        "    return X_train_processed, X_test_processed\n",
        "\n",
        "X_train, X_test = cluster_amenities_with_bert(X_train, X_test, max_k=5)"
      ],
      "metadata": {
        "id": "7dVRQrmekqYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import f_oneway\n",
        "from collections import defaultdict\n",
        "\n",
        "def get_top_amenities_by_anova(X_train, y_train, top_n=10):\n",
        "    \"\"\"\n",
        "    Identifies the top N most influential amenities on price using an ANOVA F-test,\n",
        "    including p-values for significance.\n",
        "\n",
        "    Args:\n",
        "        X_train (pd.DataFrame): Training features with an 'amenities' column.\n",
        "        y_train (pd.Series): Training target (e.g., 'log_price').\n",
        "        top_n (int): The number of top amenities to return.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame with columns for 'f_statistic' and 'p_value',\n",
        "                      indexed by amenity name, sorted by F-statistic.\n",
        "    \"\"\"\n",
        "    print(\"--- Finding Top Amenities using ANOVA ---\")\n",
        "\n",
        "    train_full = pd.concat([X_train, y_train], axis=1)\n",
        "    target_name = y_train.name\n",
        "\n",
        "    amenities_series = train_full['amenities'].fillna('').str.lower().str.strip()\n",
        "    amenities_df = amenities_series.str.get_dummies(sep=',')\n",
        "\n",
        "    anova_results = {}\n",
        "\n",
        "    for amenity in amenities_df.columns:\n",
        "        group_with_amenity = train_full[amenities_df[amenity] == 1][target_name]\n",
        "        group_without_amenity = train_full[amenities_df[amenity] == 0][target_name]\n",
        "\n",
        "        if len(group_with_amenity) > 1 and len(group_without_amenity) > 1:\n",
        "            f_stat, p_value = f_oneway(group_with_amenity, group_without_amenity)\n",
        "            anova_results[amenity] = {'f_statistic': f_stat, 'p_value': p_value}\n",
        "\n",
        "    if not anova_results:\n",
        "        return pd.DataFrame(columns=['f_statistic', 'p_value'])\n",
        "\n",
        "    results_df = pd.DataFrame.from_dict(anova_results, orient='index')\n",
        "    results_df = results_df.sort_values(by='f_statistic', ascending=False)\n",
        "\n",
        "    print(f\"ANOVA complete. Found {len(results_df)} testable amenities.\")\n",
        "\n",
        "    return results_df.head(top_n)"
      ],
      "metadata": {
        "id": "zkZMyJ-a4DMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_ranked_amenities = get_top_amenities_by_anova(X_train, y_train, top_n=50)\n",
        "\n",
        "print(\"\\n Top 50 Most Influential Amenities (by F-statistic)\")\n",
        "print(all_ranked_amenities)\n",
        "\n",
        "significance_level = 0.05\n",
        "significant_amenities = all_ranked_amenities[all_ranked_amenities['p_value'] < significance_level]\n",
        "\n",
        "print(f\"\\n Statistically Significant Amenities (p < {significance_level})\")\n",
        "if significant_amenities.empty:\n",
        "    print(\"No statistically significant amenities found at this level.\")\n",
        "else:\n",
        "    print(significant_amenities)"
      ],
      "metadata": {
        "id": "jjvxOReC4EVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a mapping dictionary\n",
        "amenities_mapping = {\n",
        "    \"TV\": [\"Cable TV\", \"TV\"],\n",
        "    \"Smart lock\": [\"Smart lock\", \"Smartlock\"],\n",
        "    \"Doorman\": [\"Doorman\", \"Doorman Entry\"],\n",
        "    \"Firm mattress\": [\"Firm matress\", \"Firm mattress\"],\n",
        "    \"Elevator\": [\"Elevator\", \"Elevator in building\"],\n",
        "    \"Grab-rails for shower and toilet\": [\"Grab-rails for shower and toilet\", \"Fixed grab bars for shower & toilet\"],\n",
        "    \"Wide clearance to shower and toilet\": [\"Wide clearance to shower & toilet\", \"Wide clearance to shower and toilet\"],\n",
        "    \"Washer\": [\"Washer\", \"Washer / Dryer\"],\n",
        "    \"Dryer\": [\"Dryer\", \"Washer / Dryer\"],\n",
        "    \"Wide clearance\": [\"Wide clearance to bed\", \"Wide doorway\", \"Wide entryway\", \"Wide hallway clearance\"],\n",
        "    \"Internet\": [\"Wireless Internet\", \"Internet\", \"Ethernet connection\", \"Pocket wifi\"],\n",
        "    \"Flat smooth pathway to front door\": [\"Flat smooth pathway to front door\", \"smooth pathway to front door\"]\n",
        "}\n",
        "\n",
        "# Function to map amenities to their unified categories\n",
        "def map_amenities(amenities_list):\n",
        "    amenities_list = amenities_list.split(',')\n",
        "    mapped_amenities = []\n",
        "    for amenity in amenities_list:\n",
        "        amenity = amenity.strip()\n",
        "        for key, values in amenities_mapping.items():\n",
        "            if amenity in values:\n",
        "                mapped_amenities.append(key)\n",
        "                break\n",
        "        else:\n",
        "            mapped_amenities.append(amenity)\n",
        "    return ', '.join(sorted(set(mapped_amenities)))\n",
        "\n",
        "X_train['amenities'] = X_train['amenities'].apply(map_amenities)\n",
        "X_test['amenities'] = X_test['amenities'].apply(map_amenities)\n",
        "\n",
        "X_train['amenities_list'] = X_train['amenities'].apply(lambda x: x.split(','))\n",
        "X_test['amenities_list'] = X_test['amenities'].apply(lambda x: x.split(','))\n",
        "\n",
        "all_amenities = [item.strip() for sublist in X_train['amenities_list'] for item in sublist]\n",
        "\n",
        "unique_amenities = sorted(set(all_amenities))\n",
        "\n",
        "for amenity in unique_amenities:\n",
        "    print(amenity)"
      ],
      "metadata": {
        "id": "sKPBBzWQ4LJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head(5)"
      ],
      "metadata": {
        "id": "NTjxsHdH6f8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_amenities_by_category(X_train, X_test, categories):\n",
        "    \"\"\"\n",
        "    Encodes a comma-separated amenities string into new columns representing\n",
        "    the count of amenities per user-defined category.\n",
        "\n",
        "    Args:\n",
        "        X_train (pd.DataFrame): Training features with an 'amenities' column.\n",
        "        X_test (pd.DataFrame): Test features with an 'amenities' column.\n",
        "        categories (dict): A dictionary where keys are category names and\n",
        "                           values are lists of amenities in that category.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the transformed X_train and X_test DataFrames.\n",
        "    \"\"\"\n",
        "    X_train_processed = X_train.copy()\n",
        "    X_test_processed = X_test.copy()\n",
        "\n",
        "    print(\"--- Encoding Amenities into Categories ---\")\n",
        "\n",
        "    amenity_to_category_map = {}\n",
        "    for category, amenities_list in categories.items():\n",
        "        for amenity in amenities_list:\n",
        "            amenity_to_category_map[amenity.lower().strip()] = category\n",
        "\n",
        "    def count_amenities_in_categories(amenities_str):\n",
        "        \"\"\"Helper function to process one row's amenities string.\"\"\"\n",
        "        category_counts = {category: 0 for category in categories.keys()}\n",
        "\n",
        "        if not isinstance(amenities_str, str) or amenities_str == '':\n",
        "            return pd.Series(category_counts)\n",
        "\n",
        "        amenities_list = amenities_str.split(',')\n",
        "\n",
        "        for amenity in amenities_list:\n",
        "            cleaned_amenity = amenity.lower().strip()\n",
        "\n",
        "            if cleaned_amenity in amenity_to_category_map:\n",
        "                category = amenity_to_category_map[cleaned_amenity]\n",
        "                category_counts[category] += 1\n",
        "\n",
        "        return pd.Series(category_counts)\n",
        "\n",
        "    train_counts_df = X_train_processed['amenities'].apply(count_amenities_in_categories)\n",
        "    test_counts_df = X_test_processed['amenities'].apply(count_amenities_in_categories)\n",
        "\n",
        "    X_train_processed = pd.concat([X_train_processed, train_counts_df], axis=1)\n",
        "    X_test_processed = pd.concat([X_test_processed, test_counts_df], axis=1)\n",
        "\n",
        "    print(f\"Amenity encoding complete. Added {len(categories)} new feature columns.\")\n",
        "\n",
        "    return X_train_processed, X_test_processed"
      ],
      "metadata": {
        "id": "DFrSSkY26koH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories = categories = {\n",
        "    \"Safety & Accessibility\": [\n",
        "        \"24-hour check-in\", \"Carbon monoxide detector\", \"Disabled parking spot\", \"Doorman\",\n",
        "        \"Fire extinguisher\", \"First aid kit\", \"Safety card\", \"Smoke detector\", \"Stair gates\",\n",
        "        \"Step-free access\", \"Well-lit path to entrance\", \"Wheelchair accessible\",\n",
        "        \"Flat smooth pathway to front door\", \"Accessible-height bed\", \"Accessible-height toilet\",\n",
        "        \"Wide clearance\", \"Wide clearance to shower and toilet\", \"Path to entrance lit at night\"\n",
        "    ],\n",
        "    \"Entertainment & Electronics\": [\n",
        "        \"TV\", \"Game console\", \"Internet\", \"Laptop friendly workspace\"\n",
        "    ],\n",
        "    \"Basic Amenities\": [\n",
        "        \"Air conditioning\", \"Heating\", \"Essentials\", \"Bed linens\",\n",
        "        \"Extra pillows and blankets\", \"Iron\", \"Hangers\", \"Firm mattress\", \"Hot water kettle\"\n",
        "    ],\n",
        "    \"Family & Kid-Friendly\": [\n",
        "        \"Babysitter recommendations\", \"Children’s books and toys\", \"Children’s dinnerware\",\n",
        "        \"Crib\", \"High chair\", \"Pack ’n Play/travel crib\", \"Outlet covers\",\n",
        "        \"Baby bath\", \"Baby monitor\", \"Table corner guards\", \"Family/kid friendly\",\n",
        "        \"Changing table\"\n",
        "    ],\n",
        "    \"Kitchen & Dining\": [\n",
        "        \"Coffee maker\", \"Cooking basics\", \"Dishes and silverware\", \"Dishwasher\",\n",
        "        \"Microwave\", \"Oven\", \"Refrigerator\", \"Stove\", \"Water kettle\", \"BBQ grill\", \"Kitchen\",\n",
        "        \"Dryer\", \"Washer\", \"Breakfast\"\n",
        "    ],\n",
        "    \"Health & Fitness\": [\n",
        "        \"Gym\", \"Air purifier\"\n",
        "    ],\n",
        "    \"Pets\": [\n",
        "        \"Cat(s)\", \"Dog(s)\", \"Other pet(s)\", \"Pets allowed\", \"Pets live on this property\"\n",
        "    ],\n",
        "    \"Parking\": [\n",
        "        \"Free parking on premises\", \"Free parking on street\", \"EV charger\", \"Paid parking off premises\"\n",
        "    ],\n",
        "    \"Outdoor & Leisure\": [\n",
        "        \"Beach essentials\", \"Beachfront\", \"Garden or backyard\", \"Lake access\",\n",
        "        \"Patio or balcony\", \"Pool\", \"Ski in/Ski out\", \"Hot tub\", \"Waterfront\"\n",
        "    ],\n",
        "    \"Security & Entry\": [\n",
        "        \"Smart lock\", \"Keypad\", \"Lock on bedroom door\", \"Lockbox\",\n",
        "        \"Self Check-In\", \"Host greets you\"\n",
        "    ],\n",
        "    \"Bathroom Amenities\": [\n",
        "        \"Hand soap\", \"Shampoo\", \"Toilet paper\", \"Bath towel\", \"Bathtub\",\n",
        "        \"Bathtub with shower chair\", \"Handheld shower head\", \"Roll-in shower with chair\",\n",
        "        \"Shower chair\", \"Fixed grab bars for shower & toilet\", \"Hair dryer\", \"Hot water\",\n",
        "        \"Accessible-height toilet\", \"Body soap\", \"Grab-rails for shower and toilet\",\n",
        "        \"Hand or paper towel\"\n",
        "    ],\n",
        "    \"Special Features\": [\n",
        "        \"Fireplace guards\", \"Indoor fireplace\", \"Private bathroom\", \"Private entrance\",\n",
        "        \"Private living room\", \"Single level home\", \"Suitable for events\",\n",
        "        \"Long term stays allowed\", \"Luggage dropoff allowed\", \"Smoking allowed\",\n",
        "        \"Other\", \"Elevator\"\n",
        "    ],\n",
        "    \"Miscellaneous\": [\n",
        "        \"Room-darkening shades\", \"Window guards\",\n",
        "        \"Smooth pathway to front door\", \"Cleaning before checkout\",\n",
        "        \"Buzzer/wireless intercom\", \"translation missing: en.hosting_amenity_50\",\n",
        "        \"translation missing: en.hosting_amenity_49\", \"Ground floor access\"\n",
        "    ],\n",
        "    \"Uncategorized\": []\n",
        "}"
      ],
      "metadata": {
        "id": "lngvjWGz7zDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = encode_amenities_by_category(\n",
        "    X_train, X_test, categories\n",
        ")"
      ],
      "metadata": {
        "id": "YshUTMH375Yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head(5)"
      ],
      "metadata": {
        "id": "q-OElSbc8Al5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_individual_amenity_flags(X_train, X_test, individual_amenities):\n",
        "    \"\"\"\n",
        "    Creates new binary (1/0) columns for a specified list of individual amenities.\n",
        "\n",
        "    Args:\n",
        "        X_train (pd.DataFrame): Training features with an 'amenities' column.\n",
        "        X_test (pd.DataFrame): Test features with an 'amenities' column.\n",
        "        individual_amenities (list): A list of specific amenities to create\n",
        "                                     binary flag columns for.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the transformed X_train and X_test DataFrames.\n",
        "    \"\"\"\n",
        "    X_train_processed = X_train.copy()\n",
        "    X_test_processed = X_test.copy()\n",
        "\n",
        "    print(\"\\n Creating Binary Features for Individual Amenities\")\n",
        "\n",
        "    train_amenities_lower = X_train_processed['amenities'].str.lower().fillna('')\n",
        "    test_amenities_lower = X_test_processed['amenities'].str.lower().fillna('')\n",
        "\n",
        "    for amenity in individual_amenities:\n",
        "        clean_amenity_name = amenity.replace(\" \", \"_\").replace(\"/\", \"_\").replace(\"-\", \"_\")\n",
        "        col_name = f'has_{clean_amenity_name}'\n",
        "\n",
        "        # Use str.contains to check for the presence of the amenity\n",
        "        # The regex `\\b` ensures we match whole words only, e.g., 'tv' doesn't match 'cable tv'\n",
        "        search_term = r'\\b' + amenity.lower() + r'\\b'\n",
        "        X_train_processed[col_name] = train_amenities_lower.str.contains(search_term, regex=True).astype(int)\n",
        "        X_test_processed[col_name] = test_amenities_lower.str.contains(search_term, regex=True).astype(int)\n",
        "\n",
        "    print(f\"✅ Added {len(individual_amenities)} new binary feature columns.\")\n",
        "    return X_train_processed, X_test_processed\n",
        "\n",
        "individual_amenities_list = [\n",
        "    \"family/kid friendly\", \"tv\", \"cable tv\", \"dryer\", \"indoor fireplace\",\n",
        "    \"washer\", \"lock on bedroom door\", \"doorman\", \"hair dryer\",\n",
        "    \"suitable for events\", \"gym\", \"private entrance\", \"24-hour check-in\",\n",
        "    \"heating\", \"elevator\"\n",
        "]\n",
        "X_train, X_test = create_individual_amenity_flags(X_train, X_test, individual_amenities_list)"
      ],
      "metadata": {
        "id": "eUuwJpE08IA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.info()"
      ],
      "metadata": {
        "id": "QJkl_BWa-kIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_remove = ['neighbourhood', 'amenities', 'amenities_list']\n",
        "X_train = X_train.drop(columns=cols_to_remove)\n",
        "X_test = X_test.drop(columns=cols_to_remove)\n",
        "\n",
        "display(X_train.head())"
      ],
      "metadata": {
        "id": "O8L9lrp0-n-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols = ['property_type', 'room_type', 'bed_type', 'cancellation_policy', 'city']\n",
        "\n",
        "X_train = pd.get_dummies(X_train, columns=categorical_cols, drop_first=True)\n",
        "X_test = pd.get_dummies(X_test, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "print(\"One-hot encoding complete.\")\n",
        "display(X_train.head())"
      ],
      "metadata": {
        "id": "k4pJ045F_JSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.info()"
      ],
      "metadata": {
        "id": "sKiAARKV_daN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_near_zero_variance(X_train, X_test, threshold=0.01):\n",
        "    \"\"\"\n",
        "    Identifies and removes features with near-zero variance from the training\n",
        "    and test sets.\n",
        "\n",
        "    Args:\n",
        "        X_train (pd.DataFrame): The training features DataFrame.\n",
        "        X_test (pd.DataFrame): The test features DataFrame.\n",
        "        threshold (float): The variance threshold. Features with variance below\n",
        "                           this value will be removed.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the transformed X_train and X_test DataFrames.\n",
        "    \"\"\"\n",
        "    X_train_processed = X_train.copy()\n",
        "    X_test_processed = X_test.copy()\n",
        "\n",
        "    print(\"Removing Near-Zero Variance Features\")\n",
        "\n",
        "    numerical_cols = X_train_processed.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "    variances = X_train_processed[numerical_cols].var()\n",
        "\n",
        "    low_variance_cols = variances[variances < threshold].index.tolist()\n",
        "\n",
        "    if not low_variance_cols:\n",
        "        print(\"No near-zero variance features found.\")\n",
        "        return X_train_processed, X_test_processed\n",
        "\n",
        "    print(f\"Found {len(low_variance_cols)} near-zero variance features to remove:\")\n",
        "    for col in low_variance_cols:\n",
        "        print(f\"  - {col} (Variance: {variances[col]:.4f})\")\n",
        "\n",
        "    X_train_processed.drop(columns=low_variance_cols, inplace=True)\n",
        "    X_test_processed.drop(columns=low_variance_cols, inplace=True)\n",
        "\n",
        "    print(\"\\n Removal complete.\")\n",
        "\n",
        "    return X_train_processed, X_test_processed"
      ],
      "metadata": {
        "id": "hR5SJbjh_ewN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = remove_near_zero_variance(X_train, X_test, threshold=0.01)"
      ],
      "metadata": {
        "id": "7ZyA6P5MAD8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.info()"
      ],
      "metadata": {
        "id": "3TDNXGlKAK7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_highly_correlated_features(X_train, X_test, threshold=0.9):\n",
        "    \"\"\"\n",
        "    Identifies and removes one feature from each pair of highly correlated\n",
        "    features from the training and test sets.\n",
        "\n",
        "    Args:\n",
        "        X_train (pd.DataFrame): The training features DataFrame.\n",
        "        X_test (pd.DataFrame): The test features DataFrame.\n",
        "        threshold (float): The correlation threshold. If the absolute value of\n",
        "                           the correlation between two features is greater than\n",
        "                           this value, one of them will be removed.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the transformed X_train and X_test DataFrames.\n",
        "    \"\"\"\n",
        "    X_train_processed = X_train.copy()\n",
        "    X_test_processed = X_test.copy()\n",
        "\n",
        "    print(\"Removing Highly Correlated Features\")\n",
        "\n",
        "    numerical_cols = X_train_processed.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "    corr_matrix = X_train_processed[numerical_cols].corr().abs()\n",
        "\n",
        "    upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "\n",
        "    to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > threshold)]\n",
        "\n",
        "    if not to_drop:\n",
        "        print(\"No highly correlated features found to remove.\")\n",
        "        return X_train_processed, X_test_processed\n",
        "\n",
        "    print(f\"Found {len(to_drop)} features to remove to break highly correlated pairs:\")\n",
        "    for col in to_drop:\n",
        "        correlated_with = upper_tri[col][upper_tri[col] > threshold].index.tolist()\n",
        "        print(f\"  - Removing '{col}' (highly correlated with {correlated_with})\")\n",
        "\n",
        "    X_train_processed.drop(columns=to_drop, inplace=True)\n",
        "    X_test_processed.drop(columns=to_drop, inplace=True)\n",
        "\n",
        "    print(\"\\n Removal complete.\")\n",
        "\n",
        "    return X_train_processed, X_test_processed"
      ],
      "metadata": {
        "id": "AdMKtZZkARx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = remove_highly_correlated_features(X_train, X_test, threshold=0.9)"
      ],
      "metadata": {
        "id": "WKJWouiiAmbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "\n",
        "def perform_rfecv(X_train, y_train, X_test, estimator, min_features_to_select=1, step=1, cv=5):\n",
        "    \"\"\"\n",
        "    Performs Recursive Feature Elimination with Cross-Validation (RFE-CV) to\n",
        "    select the optimal number of features.\n",
        "\n",
        "    Args:\n",
        "        X_train (pd.DataFrame): The training features DataFrame.\n",
        "        y_train (pd.Series): The training target variable.\n",
        "        X_test (pd.DataFrame): The test features DataFrame.\n",
        "        estimator: The supervised learning estimator with a 'fit' method and a\n",
        "                   'feature_importances_' or 'coef_' attribute.\n",
        "        min_features_to_select (int): The minimum number of features to select.\n",
        "        step (int): The number of features to remove at each iteration.\n",
        "        cv (int): The number of folds for cross-validation.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "               - X_train_selected (pd.DataFrame): Training data with only selected features.\n",
        "               - X_test_selected (pd.DataFrame): Test data with only selected features.\n",
        "               - selected_features (list): The list of names of the selected features.\n",
        "    \"\"\"\n",
        "    print(\"Performing RFE with Cross-Validation\")\n",
        "\n",
        "    kfold = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
        "\n",
        "    rfecv = RFECV(\n",
        "        estimator=estimator,\n",
        "        step=step,\n",
        "        cv=kfold,\n",
        "        scoring='neg_mean_squared_error',\n",
        "        min_features_to_select=min_features_to_select,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    print(\"Fitting RFECV\")\n",
        "    rfecv.fit(X_train, y_train)\n",
        "    print(\"Fitting complete.\")\n",
        "\n",
        "    optimal_num_features = rfecv.n_features_\n",
        "    print(f\"\\nOptimal number of features found: {optimal_num_features}\")\n",
        "\n",
        "    selected_features = X_train.columns[rfecv.support_].tolist()\n",
        "    print(\"\\nSelected features:\")\n",
        "    for f in selected_features:\n",
        "        print(f\"  - {f}\")\n",
        "\n",
        "    X_train_selected = X_train[selected_features]\n",
        "    X_test_selected = X_test[selected_features]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.xlabel(\"Number of features selected\")\n",
        "    plt.ylabel(\"Cross validation score (Negative MSE)\")\n",
        "    plt.plot(range(min_features_to_select, len(rfecv.cv_results_['mean_test_score']) + min_features_to_select), rfecv.cv_results_['mean_test_score'])\n",
        "    plt.axvline(x=optimal_num_features, color='r', linestyle='--', label=f'Optimal features = {optimal_num_features}')\n",
        "    plt.title(\"RFE-CV Performance\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return X_train_selected, X_test_selected, selected_features"
      ],
      "metadata": {
        "id": "-ldn7OgcAreD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = RandomForestRegressor(n_estimators=30, random_state=42, n_jobs=-1)\n",
        "\n",
        "X_train_final, X_test_final, final_features = perform_rfecv(\n",
        "    X_train, y_train, X_test, estimator=estimator, step=5, cv=3\n",
        ")\n",
        "\n",
        "print(\"\\n--- Shape of X_train before RFE-CV:\", X_train.shape)\n",
        "print(\"--- Shape of X_train after RFE-CV:\", X_train_final.shape)"
      ],
      "metadata": {
        "id": "9X30nSY1BMKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_directory = '/content/drive/MyDrive/homestay_price/'\n",
        "\n",
        "X_train_final.to_csv(save_directory + 'X_train_final.csv', index=False)\n",
        "\n",
        "X_test_final.to_csv(save_directory + 'X_test_final.csv', index=False)\n",
        "\n",
        "print(f\"X_train_final and X_test_final saved successfully to {save_directory}\")"
      ],
      "metadata": {
        "id": "sS5Q0N7xBjjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_final.info()"
      ],
      "metadata": {
        "id": "ORRWqeXuP3Ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "zP-UExbAR3aE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from mlxtend.regressor import StackingCVRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "\n",
        "def objective_rf(trial, X, y):\n",
        "    \"\"\"Objective function for Random Forest hyperparameter tuning.\"\"\"\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "        'max_depth': trial.suggest_int('max_depth', 5, 50),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
        "        'max_features': trial.suggest_float('max_features', 0.1, 1.0),\n",
        "    }\n",
        "\n",
        "    model = RandomForestRegressor(random_state=42, n_jobs=-1, **params)\n",
        "\n",
        "    kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    score = cross_val_score(model, X, y, cv=kf, scoring='neg_mean_squared_error').mean()\n",
        "\n",
        "    return score\n",
        "\n",
        "def objective_xgb(trial, X, y):\n",
        "    \"\"\"Objective function for XGBoost hyperparameter tuning.\"\"\"\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
        "    }\n",
        "\n",
        "    model = xgb.XGBRegressor(random_state=42, n_jobs=-1, **params)\n",
        "\n",
        "    kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    score = cross_val_score(model, X, y, cv=kf, scoring='neg_mean_squared_error').mean()\n",
        "\n",
        "    return score\n",
        "\n",
        "\n",
        "def tune_models(X_train, y_train, n_trials=50):\n",
        "    \"\"\"Runs Optuna studies to find the best hyperparameters for RF and XGB.\"\"\"\n",
        "\n",
        "    print(\"Tuning RandomForest\")\n",
        "    study_rf = optuna.create_study(direction='maximize')\n",
        "    study_rf.optimize(lambda trial: objective_rf(trial, X_train, y_train), n_trials=n_trials)\n",
        "    best_params_rf = study_rf.best_params\n",
        "    print(f\"Best RF Params: {best_params_rf}\")\n",
        "\n",
        "    print(\"\\n Tuning XGBoost\")\n",
        "    study_xgb = optuna.create_study(direction='maximize')\n",
        "    study_xgb.optimize(lambda trial: objective_xgb(trial, X_train, y_train), n_trials=n_trials)\n",
        "    best_params_xgb = study_xgb.best_params\n",
        "    print(f\"Best XGB Params: {best_params_xgb}\")\n",
        "\n",
        "    return best_params_rf, best_params_xgb"
      ],
      "metadata": {
        "id": "V5O9xOzXQihz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_rf, best_xgb = tune_models(X_train_final, y_train, n_trials=10)"
      ],
      "metadata": {
        "id": "M_8oo6yAR2Yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "def train_final_stacked_model(X_train, y_train, rf_params, xgb_params):\n",
        "    print(\"Building and Training Final Stacked Ensemble\")\n",
        "\n",
        "    rf_model  = RandomForestRegressor(random_state=42, n_jobs=-1, **rf_params)\n",
        "    xgb_model = xgb.XGBRegressor(random_state=42, n_jobs=-1, **xgb_params)\n",
        "    meta_model = Ridge(random_state=42)\n",
        "\n",
        "    stack = StackingRegressor(\n",
        "        estimators=[('rf', rf_model), ('xgb', xgb_model)],\n",
        "        final_estimator=meta_model,\n",
        "        cv=5,\n",
        "        passthrough=True,\n",
        "        n_jobs=-1,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    stack.fit(X_train, y_train)\n",
        "    print(\"Stacked model training complete.\")\n",
        "    return stack\n",
        "\n",
        "# unchanged below\n",
        "best_rf_params = {\n",
        "    'n_estimators': 678, 'max_depth': 37,\n",
        "    'min_samples_split': 10, 'min_samples_leaf': 6,\n",
        "    'max_features': 0.4336999565791009\n",
        "}\n",
        "best_xgb_params = {\n",
        "    'n_estimators': 685, 'max_depth': 9,\n",
        "    'learning_rate': 0.08324843697516912,\n",
        "    'subsample': 0.7924504745698256,\n",
        "    'colsample_bytree': 0.9323549613130819,\n",
        "    'gamma': 0.3283587776863417\n",
        "}\n",
        "\n",
        "final_model = train_final_stacked_model(X_train_final, y_train, best_rf_params, best_xgb_params)\n",
        "test_predictions = final_model.predict(X_test_final)"
      ],
      "metadata": {
        "id": "S147Bp8_SSqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score"
      ],
      "metadata": {
        "id": "u0jVIakQTbT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2 = r2_score(y_test, test_predictions)\n",
        "\n",
        "print(f\"\\nR2 Score on the test set: {r2:.4f}\")"
      ],
      "metadata": {
        "id": "Rt072n7TTUmy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}